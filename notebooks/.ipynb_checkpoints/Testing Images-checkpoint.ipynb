{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage import io, data\n",
    "import cv2 #OpenCV\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "#print(\"VersÃ£o do OpenCV utilizada\\n {}\".format(cv2.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "def distribuited_fuzzy_C_means(data_batch, K, GPU_names, initial_centers, n_max_iters):\n",
    "    setup_ts = time.time()\n",
    "    number_of_gpus = len(GPU_names)\n",
    "    \n",
    "    sizes = [len(arg) for arg in np.array_split( data_batch, len(GPU_names))]\n",
    "    \n",
    "    partial_Mu_sum_list = []\n",
    "    partial_Mu_X_sum_list = []\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    with tf.name_scope('global'):\n",
    "        with tf.device('/cpu:0'):\n",
    "            all_data = tf.placeholder(data_batch.dtype, shape=(data_batch.shape), name='all_data')\n",
    "            parts = tf.split(all_data, sizes, 0)\n",
    "\n",
    "            global_centroids = tf.Variable(initial_centers)\n",
    "            \n",
    "    for GPU_num in range(number_of_gpus):\n",
    "        GPU_name = GPU_names[GPU_num]\n",
    "        \n",
    "        (X_mat) = parts[GPU_num]\n",
    "        (N, M) = X_mat.get_shape().as_list()\n",
    "  \n",
    "        with tf.name_scope('scope_' + str(GPU_num)):\n",
    "            with tf.device(GPU_name) :\n",
    "                ####\n",
    "                # In the coments we denote :\n",
    "                # => N = Number of Observations\n",
    "                # => M = Number of Dimensions\n",
    "                # => K = Number of Centers\n",
    "                ####\n",
    "                # Data for GPU GPU_num to Clusterize\n",
    "                X = tf.Variable(X_mat)\n",
    "\n",
    "                # Reshapes rep_centroids and  rep_points to format N x K x M so that \n",
    "                # the 2 matrixes have the same size\n",
    "                rep_centroids = tf.reshape(tf.tile(global_centroids, [N, 1]), [N, K, M])\n",
    "                rep_points = tf.reshape(tf.tile(X, [1, K]), [N, K, M])\n",
    "\n",
    "                # Calculates sum_squares, a matrix of size N x K\n",
    "                # This matrix is just(X-Y)^2\n",
    "                dist_to_centers = tf.sqrt( tf.reduce_sum(tf.square(tf.subtract( rep_points, rep_centroids) ), \n",
    "                                                         reduction_indices = 2) )\n",
    "                \n",
    "                # Calculates cluster_membership, a matrix of size N x K\n",
    "                tmp = tf.pow(dist_to_centers, -2 / (M - 1))\n",
    "                cluster_membership_with_nan = tf.div( tf.transpose(tmp), tf.reduce_sum(tmp, 1))\n",
    "                \n",
    "                # Error treatment for when there are zeros in count_means_aux\n",
    "                cluster_membership = tf.where(\n",
    "                    tf.is_nan(cluster_membership_with_nan), tf.zeros_like(cluster_membership_with_nan), cluster_membership_with_nan);\n",
    "                \n",
    "                MU = tf.pow(cluster_membership, M)\n",
    "                \n",
    "                # Calculates auxiliar matrixes \n",
    "                # Mu_X_sum of size \n",
    "                Mu_X_sum = tf.matmul(MU, X)\n",
    "                Mu_sum = tf.reduce_sum(MU, 1)\n",
    "                \n",
    "                partial_Mu_sum_list.append( Mu_sum )\n",
    "                partial_Mu_X_sum_list.append( Mu_X_sum )\n",
    "                \n",
    "    with tf.name_scope('global') :\n",
    "        with tf.device('/cpu:0') :\n",
    "            global_Mu_sum = tf.add_n( partial_Mu_sum_list )\n",
    "            global_Mu_X_sum = tf.transpose(  tf.add_n(partial_Mu_X_sum_list) )\n",
    "            \n",
    "            new_centers = tf.transpose( tf.div(global_Mu_X_sum, global_Mu_sum) )\n",
    "            \n",
    "            update_centroid = tf.group( global_centroids.assign(new_centers) )\n",
    "        \n",
    "    setup_time = float( time.time() - setup_ts )\n",
    "    initialization_ts = time.time()\n",
    "    \n",
    "    config = tf.ConfigProto( allow_soft_placement = True )\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "    with tf.Session( config = config ) as sess:\n",
    "        initialization_ts = time.time()\n",
    "        sess.run(tf.global_variables_initializer(), feed_dict={all_data: data_batch})\n",
    "        initialization_time = float( time.time() - initialization_ts ) \n",
    "    \n",
    "        computation_time = 0.0\n",
    "        for i in range(n_max_iters):\n",
    "            aux_ts = time.time()\n",
    "            [result, _] = sess.run([global_centroids, update_centroid])\n",
    "            computation_time += float(time.time() - aux_ts)\n",
    "    \n",
    "    end_resut = {   'end_center'          : result             ,\n",
    "                    'init_center'         : initial_centers    ,\n",
    "                    'setup_time'          : setup_time         ,\n",
    "                    'initialization_time' : initialization_time,\n",
    "                    'computation_time'    : computation_time   ,\n",
    "                    'n_iter'              : i+1\n",
    "                }\n",
    "    return end_resut\n",
    "\n",
    "def distribuited_k_means(data_batch, K, GPU_names, initial_centers, n_max_iters):\n",
    "    setup_ts = time.time()\n",
    "    number_of_gpus = len(GPU_names)\n",
    "\n",
    "    sizes = [len(arg) for arg in np.array_split( data_batch, len(GPU_names))]\n",
    "    \n",
    "    partial_directions = []\n",
    "    partial_values = []\n",
    "    partial_results = []\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    with tf.name_scope('global'):\n",
    "        with tf.device('/cpu:0'):\n",
    "            all_data = tf.placeholder(data_batch.dtype, shape=(data_batch.shape), name='all_data')\n",
    "            parts = tf.split(all_data, sizes, 0)\n",
    "\n",
    "            global_centroids = tf.Variable(initial_centers)\n",
    "            \n",
    "    for GPU_num in range(len(GPU_names)):\n",
    "        GPU_name = GPU_names[GPU_num]\n",
    "            \n",
    "        (X_mat) = parts[GPU_num]\n",
    "        (N, M) = X_mat.get_shape().as_list()\n",
    "        \n",
    "        with tf.name_scope('scope_' + str(GPU_num)):\n",
    "            with tf.device(GPU_name) :\n",
    "                ####\n",
    "                # In the coments we denote :\n",
    "                # => N = Number of Observations\n",
    "                # => M = Number of Dimensions\n",
    "                # => K = Number of Centers\n",
    "                ####\n",
    "\n",
    "                # Data for GPU GPU_num to Clusterize\n",
    "                X = tf.Variable(X_mat)\n",
    "\n",
    "                # Reshapes rep_centroids and rep_points to format N x K x M so that \n",
    "                # the 2 matrixes have the same size\n",
    "                rep_centroids = tf.reshape(tf.tile(global_centroids, [N, 1]), [N, K, M])\n",
    "                rep_points = tf.reshape(tf.tile(X, [1, K]), [N, K, M])\n",
    "\n",
    "                # Calculates sum_squares, a matrix of size N x K\n",
    "                # This matrix is not sqrt((X-Y)^2), it is just(X-Y)^2\n",
    "                # Since we need just the argmin(sqrt((X-Y)^2)) wich is equal to \n",
    "                # argmin((X-Y)^2), it would be a waste of computation\n",
    "                sum_squares = tf.reduce_sum(tf.square(tf.subtract( rep_points, rep_centroids) ), axis = 2)\n",
    "\n",
    "                # Use argmin to select the lowest-distance point\n",
    "                # This gets a matrix of size N x 1\n",
    "                best_centroids = tf.argmin(sum_squares, axis = 1)\n",
    "                \n",
    "                means = []\n",
    "                for c in range(K):\n",
    "                    aux_points = tf.gather(X, tf.reshape(tf.where(tf.equal(best_centroids, c)), [1,-1]))\n",
    "                    means.append(\n",
    "                        tf.reduce_mean(aux_points, axis=[1]))\n",
    "\n",
    "                new_centroids = tf.concat(means, 0)\n",
    "                    \n",
    "            with tf.device('/cpu:0'):\n",
    "                y_count = tf.cast(\n",
    "                    tf.bincount(tf.to_int32(best_centroids), maxlength = K, minlength = K), dtype = tf.float64)\n",
    "                \n",
    "                partial_mu =  tf.multiply( tf.transpose(new_centroids), y_count )\n",
    "\n",
    "                partial_directions.append( y_count )\n",
    "                partial_values.append( partial_mu )\n",
    "                \n",
    "    with tf.name_scope('global') :\n",
    "        with tf.device('/cpu:0') :\n",
    "            sum_direction = tf.add_n( partial_directions )\n",
    "            sum_mu = tf.add_n( partial_values )\n",
    "\n",
    "            rep_sum_direction = tf.reshape(tf.tile(sum_direction, [M]), [M, K])\n",
    "            new_centers = tf.transpose( tf.div(sum_mu, rep_sum_direction) )\n",
    "\n",
    "            update_centroid = tf.group( global_centroids.assign(new_centers) )\n",
    "        \n",
    "    setup_time = float( time.time() - setup_ts )\n",
    "\n",
    "    config = tf.ConfigProto( allow_soft_placement = True )\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "    with tf.Session( config = config ) as sess:\n",
    "        initialization_ts = time.time()\n",
    "        sess.run(tf.global_variables_initializer(), feed_dict={all_data: data_batch})\n",
    "        initialization_time = float( time.time() - initialization_ts ) \n",
    "    \n",
    "        computation_time = 0.0\n",
    "        for i in range(n_max_iters):\n",
    "            aux_ts = time.time()\n",
    "            [result, centroids, _] = sess.run([global_centroids, best_centroids, update_centroid])\n",
    "            computation_time += float(time.time() - aux_ts)\n",
    "\n",
    "    end_resut = {   'end_center'          : result             ,\n",
    "                    'centroids'           : centroids          ,\n",
    "                    'init_center'         : initial_centers    ,\n",
    "                    'setup_time'          : setup_time         ,\n",
    "                    'initialization_time' : initialization_time,\n",
    "                    'computation_time'    : computation_time   ,\n",
    "                    'n_iter'              : i+1\n",
    "                }\n",
    "\n",
    "    return end_resut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.imread('../Img_Teste_Gustavo/img_vid01_0.tif', cv2.IMREAD_COLOR)\n",
    "camera_rgb = cv2.cvtColor(camera, cv2.COLOR_BGR2RGB)\n",
    "camera_rgb1 = camera_rgb\n",
    "plt.figure(1,figsize=(5,5))\n",
    "plt.title('heliponto', size=20)\n",
    "plt.imshow(camera_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camera_rgb = camera_rgb.reshape((-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A imagem em tres dimensoes R-G-B\n",
    "print(type(camera_rgb))\n",
    "print(camera_rgb.shape)\n",
    "\n",
    "camera_rgb = camera_rgb.astype(np.float64)\n",
    "GPU_names = get_available_gpus()\n",
    "print(GPU_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "points = np.random.choice(np.arange(0, camera_rgb.shape[0]), size=K, replace=False)\n",
    "centroids = camera_rgb[points, :]\n",
    "print(centroids.shape)\n",
    "print(camera_rgb[0:K, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = distribuited_fuzzy_C_means(camera_rgb, K, GPU_names, centroids, 20)\n",
    "print(results['end_center'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(5,5))\n",
    "plt.title('plantacao', size=20)\n",
    "plt.imshow(camera_rgb1)\n",
    "#plt.scatter(results['end_center'][:, 0], results['end_center'][:, 1], alpha = 1, c = (results['end_center'][1, 2:] / 255.), marker = (5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando com as imagens do video - Heliponto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('../Img_Teste_Gustavo/img_vid01_*.tif')\n",
    "\n",
    "for fname in range(len(images)):\n",
    "    print('Centroides do frame %d' % (fname))\n",
    "    img = mpimg.imread('../Img_Teste_Gustavo/img_vid01_%d.tif' % (fname))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    img1=img.copy()\n",
    "    img = img.reshape((-1,3))\n",
    "    img = img.astype(np.float64)\n",
    "    GPU_names = get_available_gpus()\n",
    "    K = 3\n",
    "    points = np.random.choice(np.arange(0, img.shape[0]), size=K, replace=False)\n",
    "    centroids = img[points, :]\n",
    "    results = distribuited_fuzzy_C_means(img, K, GPU_names, centroids, 20)\n",
    "    print(results['end_center'])\n",
    "    print('Tempo no frame %d ' % (fname))\n",
    "    print(results['computation_time'])\n",
    "    print('')\n",
    "    \n",
    "    ### com k-means do opencv - comparacao\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 2\n",
    "    img2 = img1.reshape((img1.shape[0] * img1.shape[1], 3))\n",
    "    img2 = img2.astype(np.float32)\n",
    "    start_kmeans = time.time()\n",
    "    ret,label,center=cv2.kmeans(img2,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    end = time.time()\n",
    "    tempo=(end - start_kmeans)\n",
    "    print('Tempo k-means generico no frame %d ' % (fname))\n",
    "    print(tempo)\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res = res.reshape((img1.shape[0],img1.shape[1],3))\n",
    "    res2 = img2.reshape((img1.shape[0],img1.shape[1],3))\n",
    "    plt.figure(1)\n",
    "    plt.title('k-means generico', size=15)\n",
    "    plt.imshow(np.hstack([res2, res]))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
