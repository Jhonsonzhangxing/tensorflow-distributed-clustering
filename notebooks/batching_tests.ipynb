{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lopac/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import threading\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "def make_data(filepath, n_obs, n_dim, seed, K):\n",
    "\n",
    "    try:\n",
    "        os.remove(filepath)\n",
    "    except:\n",
    "        print('file not found')\n",
    "    finally:\n",
    "        (X, Y) = make_classification(n_samples            = n_obs    , \n",
    "                                     n_features           = n_dim    ,\n",
    "                                     n_informative        = n_dim    ,\n",
    "                                     n_redundant          = 0        ,\n",
    "                                     n_classes            = K        ,\n",
    "                                     n_clusters_per_class = 1        ,\n",
    "                                     shuffle              = True     ,\n",
    "                                     class_sep            = 1.5      ,\n",
    "                                     random_state         = seed      )\n",
    "        \n",
    "        np.savez(filepath, X=X, Y=Y)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_obs = 200000000\n",
    "n_dim = 2\n",
    "K     = 3\n",
    "GPU_names = get_available_gpus()\n",
    "n_max_iters = 20\n",
    "seed = 800594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_data('test-data.npz', n_obs, n_dim, seed, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with np.load('test-data.npz') as data:\n",
    "    data_X = data['X']\n",
    "    data_Y = data['Y']\n",
    "\n",
    "    \n",
    "maxsize = 2 * 1024 * 1024 * 1024\n",
    "size_of_each = data_X.shape[1] * data_X.dtype.itemsize\n",
    "\n",
    "initial_centers = data_X[0:K, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GpuParamServerDeviceSetter(object):\n",
    "    \"\"\"Used with tf.device() to place variables on the least loaded GPU.\n",
    "    \n",
    "    A common use for this class is to pass a list of GPU devices, e.g. ['gpu:0',\n",
    "    'gpu:1','gpu:2'], as ps_devices.  When each variable is placed, it will be\n",
    "    placed on the least loaded gpu. All other Ops, which will be the computation\n",
    "    Ops, will be placed on the worker_device.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, worker_device, ps_devices):\n",
    "        \"\"\"Initializer for GpuParamServerDeviceSetter\n",
    "        Args:\n",
    "        worker_device: the device to use for computation Ops.\n",
    "        ps_devices: a list of devices to use for Variable Ops. Each variable is\n",
    "        assigned to the least loaded device.\n",
    "        \"\"\"\n",
    "        self.ps_devices = ps_devices\n",
    "        self.worker_device = worker_device\n",
    "        self.ps_sizes = [0] * len(self.ps_devices)\n",
    "\n",
    "    def __call__(self, op):\n",
    "        if op.device:\n",
    "            return op.device\n",
    "        if op.type not in ['Variable', 'VariableV2', 'VarHandleOp']:\n",
    "            return self.worker_device\n",
    "\n",
    "        # Gets the least loaded ps_device\n",
    "        device_index, _ = min(enumerate(self.ps_sizes), key=operator.itemgetter(1))\n",
    "        device_name = self.ps_devices[device_index]\n",
    "        var_size = op.outputs[0].get_shape().num_elements()\n",
    "        self.ps_sizes[device_index] += var_size\n",
    "        \n",
    "        return device_name\n",
    "\n",
    "def _create_device_setter(is_cpu_ps, worker, num_gpus):\n",
    "    \"\"\"Create device setter object.\"\"\"\n",
    "    if is_cpu_ps:\n",
    "        # tf.train.replica_device_setter supports placing variables on the CPU, all\n",
    "        # on one GPU, or on ps_servers defined in a cluster_spec.\n",
    "        return tf.train.replica_device_setter(\n",
    "            worker_device=worker, ps_device='/cpu:0', ps_tasks=1)\n",
    "    else:\n",
    "        gpus = ['/gpu:%d' % i for i in range(num_gpus)]\n",
    "        return GpuParamServerDeviceSetter(worker, gpus)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_batch(dataset, batch_size):\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    data_batch = iterator.get_next()\n",
    "    \n",
    "def tower_fn(data_batch, K, initial_centers, max_iters):\n",
    "    ####\n",
    "    # In the coments we denote :\n",
    "    # => N = Number of Observations\n",
    "    # => M = Number of Dimensions\n",
    "    # => K = Number of Centers\n",
    "    ####\n",
    "    \n",
    "    # Reshapes rep_centroids and rep_points to format N x K x M so that \n",
    "    # the 2 matrixes have the same size\n",
    "    rep_centroids = tf.reshape(tf.tile(global_centroids, [N, 1]), [N, K, M])\n",
    "    rep_points = tf.reshape(tf.tile(X, [1, K]), [N, K, M])\n",
    "\n",
    "    # Calculates sum_squares, a matrix of size N x K\n",
    "    # This matrix is not sqrt((X-Y)^2), it is just(X-Y)^2\n",
    "    # Since we need just the argmin(sqrt((X-Y)^2)) wich is equal to \n",
    "    # argmin((X-Y)^2), it would be a waste of computation\n",
    "    sum_squares = tf.reduce_sum(tf.square(tf.subtract( rep_points, rep_centroids) ), axis = 2)\n",
    "\n",
    "    # Use argmin to select the lowest-distance point\n",
    "    # This gets a matrix of size N x 1\n",
    "    best_centroids = tf.argmin(sum_squares, axis = 1)\n",
    "                    \n",
    "    means = []\n",
    "    for c in range(K):\n",
    "        means.append(\n",
    "            tf.reduce_mean(\n",
    "                tf.gather(X, tf.reshape(tf.where(tf.equal(best_centroids, c)), [1,-1])), axis=[1]))\n",
    "\n",
    "        \n",
    "    new_centroids = tf.concat(means, 0)\n",
    "    \n",
    "    return best_centroids, new_centroids\n",
    "\n",
    "def input_fn(data, batch_size, num_gpus):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    data_iterator = iterator.get_next()\n",
    "    \n",
    "    dataset = tf.unstack(dataset, num=batch_size, axis=0)\n",
    "    dataset_shards = [[] for i in range(num_gpus)]\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        idx = i % num_gpus\n",
    "        dataset_shards[idx].append(dataset[i])\n",
    "        \n",
    "    dataset_shards = [tf.paralel_stack(x) for x in dataset_shards]\n",
    "    return dataset_shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distributed_kmeans(GPU_names, num_items, initial_centers, batch_data, max_iters):\n",
    "    partial_directions = []\n",
    "    partial_values = []\n",
    "    partial_results = []\n",
    "    \n",
    "    with tf.name_scope('training_data'):\n",
    "        with tf.device('/cpu:0'):\n",
    "            parts = batch_data.shard(batch_data, len(GPU_names), 0)\n",
    "\n",
    "            global_centroids = tf.Variable(initial_centers, name=\"global_centroids\")\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    is_cpu_ps = True\n",
    "    \n",
    "    for i in range(len(GPU_names)):\n",
    "        worker = GPU_names[i]\n",
    "        \n",
    "        device_setter = _create_device_setter(is_cpu_ps, worker, len(GPU_names))\n",
    "        \n",
    "        (X) = batch_data\n",
    "        (N, M) = X.get_shape().as_list()\n",
    "        \n",
    "        with tf.variable_scope('training_data', reuse=bool(i != 0)):\n",
    "            with tf.name_scope('tower_%d' % i) as name_scope:\n",
    "                \n",
    "                with tf.device(device_setter):\n",
    "                    \n",
    "                    ####\n",
    "                    # In the coments we denote :\n",
    "                    # => N = Number of Observations\n",
    "                    # => M = Number of Dimensions\n",
    "                    # => K = Number of Centers\n",
    "                    ####\n",
    "\n",
    "                    # Reshapes rep_centroids and rep_points to format N x K x M so that \n",
    "                    # the 2 matrixes have the same size\n",
    "                    rep_centroids = tf.reshape(tf.tile(global_centroids, [N, 1]), [N, K, M])\n",
    "                    rep_points = tf.reshape(tf.tile(X, [1, K]), [N, K, M])\n",
    "\n",
    "                    # Calculates sum_squares, a matrix of size N x K\n",
    "                    # This matrix is not sqrt((X-Y)^2), it is just(X-Y)^2\n",
    "                    # Since we need just the argmin(sqrt((X-Y)^2)) wich is equal to \n",
    "                    # argmin((X-Y)^2), it would be a waste of computation\n",
    "                    sum_squares = tf.reduce_sum(tf.square(tf.subtract( rep_points, rep_centroids) ), axis = 2)\n",
    "\n",
    "                    # Use argmin to select the lowest-distance point\n",
    "                    # This gets a matrix of size N x 1\n",
    "                    best_centroids = tf.argmin(sum_squares, axis = 1)\n",
    "                    \n",
    "                    means = []\n",
    "                    for c in range(K):\n",
    "                        means.append(\n",
    "                            tf.reduce_mean(\n",
    "                                tf.gather(X, tf.reshape(tf.where(tf.equal(best_centroids, c)), [1,-1])), axis=[1]))\n",
    "\n",
    "                    new_centroids = tf.concat(means, 0)\n",
    "                    \n",
    "                with tf.device('/cpu:0'):\n",
    "                    y_count = tf.cast(\n",
    "                        tf.bincount(tf.to_int32(best_centroids), maxlength = K, minlength = K), dtype = tf.float64)\n",
    "            \n",
    "                    partial_mu =  tf.multiply( tf.transpose(new_centroids), y_count )\n",
    "\n",
    "                    partial_directions.append( y_count )\n",
    "                    partial_values.append( partial_mu )\n",
    "                    \n",
    "    with tf.name_scope('aggregation') :\n",
    "        with tf.device('/cpu:0') :\n",
    "            sum_direction = tf.add_n( partial_directions )\n",
    "            sum_mu = tf.add_n( partial_values )\n",
    "\n",
    "            rep_sum_direction = tf.reshape(tf.tile(sum_direction, [M]), [M, K])\n",
    "            new_centers = tf.transpose( tf.div(sum_mu, rep_sum_direction) )\n",
    "\n",
    "            update_centroid = tf.group( global_centroids.assign(new_centers) )\n",
    "    \n",
    "    for i in range(n_max_iters):\n",
    "        [result, _] = [global_centroids, update_centroid]\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:0\", shape=(?, 2), dtype=float64)\n",
      "initial:  [[-0.75325731 -2.2329732 ]\n",
      " [ 1.23589105  1.48353633]\n",
      " [ 1.35603883  1.57902516]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9056e79cd50e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed_kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPU_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_centers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_max_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-42453b16aac3>\u001b[0m in \u001b[0;36mdistributed_kmeans\u001b[0;34m(GPU_names, num_items, initial_centers, batch_data, max_iters)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mglobal_centroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_centers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"global_centroids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPU_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \"\"\"\n\u001b[0;32m-> 2042\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4488\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4489\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4490\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 run_metadata):\n\u001b[1;32m   1292\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1354\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_placeholder = tf.placeholder(data_X.dtype, data_X.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data_placeholder)\n",
    "num_items = np.floor(maxsize / size_of_each)\n",
    "dataset = dataset.batch(num_items)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "config = tf.ConfigProto( allow_soft_placement = True )\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "with tf.Session(config = config) as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={data_placeholder: data_X})\n",
    "    print(next_element)\n",
    "\n",
    "    print('initial: ', initial_centers)\n",
    "    while True:\n",
    "        try:\n",
    "            item = sess.run(distributed_kmeans(GPU_names, num_items, initial_centers, next_element, n_max_iters))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
